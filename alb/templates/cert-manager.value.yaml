global:
  imagePullSecrets: []
  # - name: "image-pull-secret"

  priorityClassName: "system-cluster-critical"
  rbac:
    create: true

  podSecurityPolicy:
    enabled: true
    useAppArmor: true

  # Set the verbosity of cert-manager. Range of 0 - 6 with 6 being the most verbose.
  logLevel: 2

  leaderElection:
    namespace: "kube-system"
    # leaseDuration: 60s
    # renewDeadline: 40s
    # retryPeriod: 15s

installCRDs: false
replicaCount: 1

# Comma separated list of feature gates that should be enabled on the
# controller pod.
featureGates: ""

serviceAccount:
  create: true
  # name: ""
  # annotations: {}

extraArgs:
  - --cluster-resource-namespace=kube-system
  - --enable-certificate-owner-ref=true

extraEnv: []
# - name: SOME_VAR
#   value: 'some value'

resources:
  limits:
    memory: 100Mi
  requests:
    cpu: 30m
    memory: 100Mi

volumes: []

volumeMounts: []

# Optional DNS settings, useful if you have a public and private DNS zone for
# the same domain on Route 53. What follows is an example of ensuring
# cert-manager can access an ingress or DNS TXT records at all times.
# NOTE: This requires Kubernetes 1.10 or `CustomPodDNS` feature gate enabled for
# the cluster to work.
# podDnsPolicy: "None"
# podDnsConfig:
#   nameservers:
#     - "1.1.1.1"
#     - "8.8.8.8"

ingressShim: {}
  # defaultIssuerName: ""
  # defaultIssuerKind: ""
  # defaultIssuerGroup: ""

# Prometheus service monitoring setup
prometheus:
  enabled: true
  servicemonitor:
    enabled: false
    prometheusInstance: default
    targetPort: 9402
    path: /metrics
    interval: 60s
    scrapeTimeout: 30s
    labels: {}

# Use these variables to configure the HTTP_PROXY environment variables
# http_proxy: "http://proxy:8080"
# http_proxy: "http://proxy:8080"
# no_proxy: 127.0.0.1,localhost

affinity:
  nodeAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      nodeSelectorTerms:
        - matchExpressions:
          - key: role
            operator: In
            values:
            - operator
  podAntiAffinity:
    requiredDuringSchedulingIgnoredDuringExecution:
      - labelSelector:
          matchExpressions:
          - key: app
            operator: In
            values:
            - cert-manager
        topologyKey: topology.kubernetes.io/zone
tolerations:
  - key: operator
    operator: Equal
    value: "true"
    effect: NoSchedule

webhook:
  replicaCount: 1
  timeoutSeconds: 10

  resources:
    limits:
      memory: 100Mi
    requests:
      cpu: 10m
      memory: 100Mi

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: role
              operator: In
              values:
              - operator
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - webhook
          topologyKey: topology.kubernetes.io/zone

  tolerations:
    - key: operator
      operator: Equal
      value: "true"
      effect: NoSchedule

  serviceAccount:
    create: true
    # name: ""
    # annotations: {}

  # The port that the webhook should listen on for requests.
  # In GKE private clusters, by default kubernetes apiservers are allowed to
  # talk to the cluster nodes only on 443 and 10250. so configuring
  # securePort: 10250, will work out of the box without needing to add firewall
  # rules or requiring NET_BIND_SERVICE capabilities to bind port numbers <1000
  securePort: 10250

  # Specifies if the webhook should be started in hostNetwork mode.
  #
  # Required for use in some managed kubernetes clusters (such as AWS EKS) with custom
  # CNI (such as calico), because control-plane managed by AWS cannot communicate
  # with pods' IP CIDR and admission webhooks are not working
  #
  # Since the default port for the webhook conflicts with kubelet on the host
  # network, `webhook.securePort` should be changed to an available port if
  # running in hostNetwork mode.
  hostNetwork: false

cainjector:
  enabled: true
  replicaCount: 1

  resources:
    limits:
      memory: 100Mi
    requests:
      cpu: 10m
      memory: 100Mi

  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
          - matchExpressions:
            - key: role
              operator: In
              values:
              - operator
    podAntiAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        - labelSelector:
            matchExpressions:
            - key: app
              operator: In
              values:
              - cainjector
          topologyKey: topology.kubernetes.io/zone
  tolerations:
    - key: operator
      operator: Equal
      value: "true"
      effect: NoSchedule

  serviceAccount:
    create: true
    # name: ""
    # annotations: {}
